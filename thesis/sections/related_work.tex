\section{Related work}
\label{sec:related_work}

There is a lot of work about variations of null pointer consistency check available in the open-source world.
The most relevant and closely related work that is based on an universal representation is the micro-grammar approach \cite{Brown:2016:BSC:2954679.2872364} that we will discuss in subsection \ref{subsec:micro_grammar}.
In subsection \ref{subsec:other_tools_technology}, we will present the different techniques that other popular tools use to perform null pointer dereference check and discuss the differences with other popular tools in subsection \ref{subsec:other_tools_features}.
None of them implements the checks on an universal language, but it is a good way to understand the technologies that they use to perform the checks, and anticipate the problems that can arise if we want to implement equivalent features on \slang{}.

\subsection{Micro-grammar}
\label{subsec:micro_grammar}

How to Build Static Checking Systems Using Orders of Magnitude Less Code \cite{Brown:2016:BSC:2954679.2872364} is raising a similar concern that we tried to solve. 
They observed that the current situation makes it hard to target new languages due to the complexity of the current systems. 
The main idea is similar to \slang{}, they implemented a checker that is based on an incomplete grammar, that is called \textbf{micro-grammar}.
With this approach, they managed to implement a checker that is order of magnitude smaller than typical systems.
The results that they obtain is encouraging, they manage to find hundreds of issues with an acceptable false positive rate. 
The idea is similar to island parsing \cite{Moonen:2001}, where the grammar only describes some part of a language, without requirement to have the whole syntax, enabling the tool to be fast, flexible and robust when confronted to unexpected language features.

\begin{table}[h]
	\centering
	\caption{Issues reported on OpenJDK 8b132 by the micro-grammar approach}
	\label{table:micro_grammar_issues}
	\begin{tabular}{|c|c|c|}
		\hline
		\bf Issues & \bf False positives & \bf \% \\ \hline
		42 &  3 &  7 \\ \hline
	\end{tabular}
\end{table}

\begin{table}[h]
	\centering
	\caption{Issues reported on OpenJDK 8b132 by \slang{}}
	\label{table:slang_issues_jdk8}
	\begin{tabular}{|c|c|c|}
		\hline
		\bf Issues & \bf False positives & \bf \% \\ \hline
		28 &  0 &  0 \\ \hline
	\end{tabular}
\end{table}

Table \ref{table:micro_grammar_issues} and \ref{table:slang_issues_jdk8} are showing the number of issues reported by the micro-grammar approach and \slang{} on OpenJDK 8b132.
By reporting no false positive on Java code, our implementation performs better than the micro-grammar that reports an already very low rate.
However, our implementation reports less issues.
Unfortunately, the paper does not provide the list of issues reported to help us identify the one that we are missing.
One probable explanation is that we choose to only report the issues that come from local identifier (subsection \ref{subsubsec:identifying_local_variable}), this approach does not report any false positive, at the cost of few false negative.
Both results are more or less similar, and both works reach the conclusion that it is possible to find interesting issues with an universal approach.

\subsection{Technology used by other tools}
\label{subsec:other_tools_technology}

If the initial goal is not to find as many issues as any other tool, looking at the features they provide is a good way to know how to improve the current checker and to anticipate if it is possible to implement them on top of \slang{}.

\begin{table}[h]
	\centering
	\caption{Tools that detect \emph{null} pointer dereference}
	\label{table:tools_features}
	\begin{tabular}{|l|}
		\hline
		\bf Tools \\
		\hline
		SonarJava \cite{SonarJava:2019:Online} \\
		FindBugs \cite{Hovemeyer:2004:FBE:1052883.1052895} and SpotBugs \cite{spotBugs:2019:Online} \\
		Fbinfer \cite{fbInfer:2019:Online} \\
		ErrorProne \cite{errorProne:2019:Online} \\
		IntelliJ IDEA \cite{intelJIDEA:2019:Online} \\
		\hline    
	\end{tabular}
\end{table}

Table \ref{table:tools_features} shows the list of tools that detect \emph{null} pointer dereference, that we can use to compare and understand the different technologies that are currently used.
A first observation of these tools shows that they are globally using similar technology, with different level of efficiency.
Our tool is however implementing only a fraction of these technology, mainly due to the fact that we did not target them in the first place since we tried to not become too complex. 
The next parts will discuss the main features that are used by others tools, for what this technology is good for, and if we can implement it on \slang{}.

\subsubsection{Interprocedural}
\label{subsubsec:inter_procedrual}

Our current checker is only supporting intraprocedural analysis, going further is obviously a way to find more issue, since it would enable us to learn belief from arguments not only inside one function, but also outside it.
The main difficulty is to define which function is called at run time, if it is possible to do it for one language, having a consistent way to do it in a language agnostic way is a real challenge. 
One of the way is to compute the summary of every function, and to use this information during the intraprocedural analysis. 
For example, we can store for every function if it can return \emph{null}, then when the result of this function call is assigned to a variable, we can consider it the same way as if it was \emph{null}. 
This idea is used by SpotBugs and will be described in subsection \ref{subsec:spotbugs_specific}. 
There is multiple other ways to perform interprocedural analysis, that represents more precisely the execution flow, however the ideas are complex and will not be described in this work.

\subsubsection{Requires the build}
\label{subsubsec:require_build}

Requiring the build can be perceived as a disadvantage, since compiling code and calling it static analysis seems to be a contradiction.
Using the build provides however so much information that the popular tools seems to all have opted for it.
This can make sense when the checking for error is integrated to the build process, but this is a real handicap when we want to have interactive feedback in an IDE or a pull request analysis, and is not possible in a cloud computing scenario, when you do not have access to the binaries. 
The recent trend however is to avoid using the build due to the disadvantage stated before.

In the situation of \slang{}, we will obviously requiring to have access to the binaries of the original language does not make a lot of sense, since it will contradict everything that is already in place.
In addition, the goal of \slang{} is not to be a complete language, it is therefore far from being possible to compile this new code. 
This adds a new challenge that \slang{} will probably face in the future, but it brings enough benefits to make the effort worth it.

\subsubsection{Guided by annotation}
\label{subsubsec:guided_by_annotation}

We have seen in section \ref{subsubsec:inter_procedrual} that interprocedural analysis is difficult operation, to help to reduce the complexity of the analysis, we can use annotation to help the tool report possible problems. 
Annotation are typically used to declare that a function can return a \emph{null} value, or that a function should never be called with \emph{null} as argument.

\lstinputlisting[label={lst:annotated-code},
caption=Example of annotated code]{code/annotated-code.scala}

In listing \ref{lst:annotated-code} for example, the function \emph{f} is guaranteed to never return \emph{null}, and the callee can directly dereference the result of this function without further checking..
For the parameters, it enforces that \emph{f} can give \emph{null} as a first parameter, but not for the second one.\newline
They are multiple flavor on how to do it, depending on what we want, for example, Error Prone is using a trusting analysis, meaning that method parameters, field, and method return are assumed \nullable{} only if annotated so. 
If we see the problem the other way, we could alternatively ask to explicitly mark as \emph{non-null} an argument that should never be \emph{null}.\newline
Annotations seem to be the most popular way to detect \emph{null} pointer exception currently, especially for interactive tools, it enables to detect most of the exceptions with a small effort on the programmer side. 
It is often worth to make this effort, it is useful not only for the checker, but also helps during the development of the program.
The downside of this method is that it requires a consistent and coordinate use of annotation in a whole project, consistency that is hard to achieve, even more when we want to introduce it in an old project.

Annotation could be added on top of \slang{}, finding annotation that are relevant for any language is possible if they share the same concepts. 
For example, a \emph{non-null} annotation makes sense in any language that has the concept of \emph{null}. 
In other cases, this can be more tricky; for example, the annotation \emph{initializer}, used in the context of \emph{null} pointer exception, can not be used in an language agnostic way, since the initialization is not the same in any language.\newline
One solution to this is to provide a way to configure the tool. 
Using configurable check is always a danger for the user experience. For example, NullAway is providing more than 10 configuration flags, some of them being mandatory, all of them related to \emph{null} dereference. 
In the context of \slang{}, having so much configuration to do for every checks and every language simply does not scale at all.\newline
An interesting note is that annotation are principally used is to help to reduce the complexity of the analysis, however no annotation is required to detect all pointer if we have a perfect interprocedural analysis.

\subsubsection{Path sensitivity}
\label{subsubsec:path_sensitivity}

Currently, our tool is using flow sensitive analysis, meaning that we are only interested in the order in which the statements are executed.
In addition, path-sensitivity computes and keeps additional information, based on statements seen along the path and avoid infeasible path. 
For example, if a pointer is checked for \emph{null}, the tool will know that the pointer is equals to \emph{null} inside the true branch, it will therefore report if the pointer is used or given to a function that expect a \emph{non-null} value.
For our purpose, we could also learn the value of a given pointer with assignment for example.

\lstinputlisting[label={lst:simple-np},
caption=Simple example of null pointer exception]{code/simple-np.scala}

Listing \ref{lst:simple-np} shows a simple code that obviously raise an exception. Our checker is currently not able to detect it, since it does not try to know the current value of a pointer.
Path sensitive tools would be able to find this kind of issues.
In addition, we could also use the path sensitivity to improve the \emph{MAY} analysis introduce in subsection \ref{subsubsec:may_vs_must}, to remove the obvious false positives. 
The main challenge of this kind of analysis is to deal with the fact that the number of path grow exponentially, making it hard to scale. 
In the current situation, we do not have path-sensitivity in our checker, but we already have all the features required, implementing it with the same constraints as an implementation over a original language seem to be possible.

\subsection{Popular tools}
\label{subsec:other_tools_features}

None of the popular tools are based on an incomplete representation, but they face challenges that can be similar to what we can experience, helping us to anticipate the potential problems that can arise in the future.

\subsubsection{IntellJ IDEA}
\label{subsubsec:intellj_idea}

IntellJ is a development environment, this is a particularly interesting since it requires interactivity, a user wants to see the issues being raised while he writes code, without having to rebuild the whole project. 
This tool is also performing a \emph{null} pointer analysis using annotation. 
It warns when the user use a pointer that is \nullable{}, without checking it for \emph{null}. 
To detect that a pointer is checked for \emph{null}, it uses a pattern that is customizable. 
This will not work if the user is using custom methods to perform the null-check. 
In this case, the user can use a contract, that would for example say that this method fail if the argument is \emph{null}, or more simply configure the custom function that perform the \emph{null} check.\newline
Having configurable setting for a check in \slang{} is far from being ideal, even if the effort to configure one check seems to be minimal, if we have a configuration to do for every rule, this can quickly becomes a nightmare for the user. 
All our work that try to reduce the overall complexity would be pointless if we have a configuration for every checks.


\subsubsection{Error prone: Null away}
\label{subsubsec:error_prone}

\emph{Null} away is a tool built on top of error prone. 
To perform \emph{null} pointer consistency, the process first checks if the value dereferenced is obviously \emph{non-null} (annotated \emph{@Non-null}). 
If it is not the case, it performs a data-flow analysis to try to infer the that the value should be annotated \emph{non-null}. 
The data-flow analysis is using existing \emph{null} check into the code, if a field is annotated as \nullable{} and is dereferenced, an error will be reported if the value is not checked for \emph{null}. \newline
The key idea here is to perform the analysis in multiple steps of increasing complexity, skipping costly part, like the creation of the control flow graph, if it is not required.
Having multiple steps is a particularly good idea for \slang{}, not only for performance, but also for the quality of the results. 
If we can report an issue, or prevent a complex computation before facing the uncertainties due to \slang{}, it may prevent us to make bad decisions.

\subsubsection{SpotBugs}
\label{subsec:spotbugs_specific}

We have seen in subsection \ref{subsec:indpeth_comparison_spotbugs} that SpotBugs is reporting way more issues related to null dereference that our implementation is reporting.
The main reason of this huge difference is mainly due to the features described previously in subsection \ref{subsec:other_tools_technology}.
In addition, we will look more in-depth into one additional feature that is implemented in SpotBugs and producing a big difference, and see if it may be implemented on \slang{}.

\subparagraph{Summary-based interprocedural analysis}
Summary-based analysis is a smart and easy first step to perform interprocedural analysis.
The idea is to compute a summary of every methods, and use this information during the intraprocedural analysis. 
In our case, we would like to store if a method can return \emph{null}, or if a parameter could be \emph{non-null} to then report if \emph{null} is passed as his argument.
We can have this information by looking at annotation, if the annotations are not present, we can still perform intraprocedural analysis to infer ourselves the annotation. 
For example, if a method ever return \emph{null}, we can annotate the function as \nullable{}, and if a function always dereference an argument without checking it for \emph{null}, we can infer that the argument is \emph{non-null}. 
The good part is that we already have the nodes and data required to build the summary, however, we are missing the method references in \slang{} to be able to implement this check.
We need to be able to identify which method is called to be able to retrieve the summary of the function that is called.
This is related to the problem of the name reference that we faced during the previous parts, naive solutions exist, but proper semantics have to be computed to obtain interesting results.

\begin{figure}[H]
	\centering
	\caption{Pseudo code of a class that extends an abstract class}
	\label{figure:class-extends-abtract}
	\setlength{\tabcolsep}{24pt}
	\begin{tabular}{cc}
		\multicolumn{1}{c}{\lstinputlisting[numbers=none,nolol=true]{code/abstract-class-1.scala}} & \multicolumn{1}{c}{\lstinputlisting[numbers=none,nolol=true]{code/abstract-class-2.scala}} \\
	\end{tabular}

\lstinputlisting[label={lst:spotbugs-true-false-positive}]{code/spotbugs-true-false-positive.scala}
\end{figure}

Method reference can be complex, that happen to be producing false negative in SpotBugs. 
In figure \ref{figure:class-extends-abtract}, we have an example of a true positive and a false negative from SpotBugs. 
At line $\#2$, the issues is correctly reported, the tool manages to identify statically that the pointer \emph{b} is called with type \emph{B}. 
At line $\#4$ however, the tool is not reporting any issue. 
This is due to the fact that the type of \emph{a} is \emph{B}, the tool is not able to identify the potential run-time type of the variable.\newline
This is clearly a challenge that we will also face in the future of \slang{}, but we have seen that there is no strong push-back to implement it, and it could already greatly increase the number of issues reported by \slang{}, even if we have the same false negative as SpotBugs.