\section{Improving SLang: Null pointer consistency}
\label{sec:improving_slang}

\slang{} has already demonstrated his power to add 4 new languages, some of them in less than a month, and to implement more than 40 common checks. 
However, the language is still young and the current checks involve mainly syntactic element. 
In this section, we are going to attend to push \slang{} further, to implement more complex checks.
To estimate the quality of the results of a checker implemented on \slang{}, we will use a variation \emph{null} pointer consistency check. 
We choose this check because this is a well-known bug and well-studied in static analysis, a lot of different implementations exist with different complexity.

\subsection{What is null pointer consistency}
\label{subsec:null_pointer_consistency}

\emph{Null} pointer consistency is the verification that a pointer who is dereferenced is valid and not equal to \emph{null}. Dereferencing a \emph{null} pointer will result at best to an abrupt program termination, and at worst could be used by an attacker, by revealing debugging information or bypassing security logic for example.

\subsection{Belief style Null Pointer Checker}
\label{subsec:belief_style}

The goal is to build a checker that implements a variation of the current check \emph{null pointers should not be dereferenced} \cite{RSPEC-2259:2019:Online}, implemented on SonarJava \cite{SonarJava:2019:Online}, the tool developed at SonarSource to perform static analysis on Java code.
The current implementation uses a complex symbolic execution engine to report potential \emph{null} pointer exception.
Symbolic execution try to estimate all possible execution paths, track the value of variables, and report when a pointer is dereferenced while it can be \emph{null} on one path.
One important limitation is that it uses a lot of assumptions to deal with the fact that the possible execution paths quickly explode. 
If it is possible to come up with good assumptions to report interesting bug, the complexity of the implementation also increase, preventing improvement and therefore the ability to find more bugs. \cite{Brown:2016:BSC:2954679.2872364}. 
Our initial goal is not to find all the issues that the implementation on SonarJava reports, but to see if it is possible to still find interesting issues with an implementation that is less complex, and based on a common intermediate representation.

The idea of this first checker is to use facts implied by the code, that we will call \textbf{belief} \cite{Engler:2001:BDB:502059.502041}.
It assumes that the programmerâ€™s goal is not to make his code crash, if two contradicting believes are detected, we report an issue.
Concretely, we are going to try to detect the use of a pointer \emph{P}, followed by a check for \emph{null}. The check for \emph{null} can be equal or not equal to \emph{null}, both statements implying that the programmer believes that the pointer \emph{P} can be \emph{null}.

\lstinputlisting[label={lst:typical-issue},
caption=Typical example that the checker reports]{code/typical-issue.scala}

Listing \ref{lst:typical-issue} demonstrates a typical example that the checker is able to report. 
From line $\#1$, \emph{p} is dereferenced without having been checked for \emph{null}, we can imply that the programmer believes that, at this point, the pointer is not \emph{null}, otherwise the program will crash. 
If later, at line $\#4$, \emph{p} is checked for \emph{null}, it implies that the programmer thinks that \emph{p} can in fact be \emph{null}, contradicting the previous belief: we report an issue from this contradiction.
To implement this check, we need to have a representation of the control flow of the program, that is typically represented by a control flow graph.

\subsubsection{Control Flow Graph}
\label{subsubsec:control_flow_graph}

A control flow graph is a directed graph that represents the execution flow of a program, the nodes of the graph are individual instructions, and the edges represent the control flow. More precisely, there is an edge from a node \emph{N1} to a node \emph{N2}, if and only if the instruction of the node \emph{N2} can be directly executed after the node \emph{N1}.


\subparagraph{Basic Block}
We initially described the nodes as individual instructions, however, we can easily see that many instruction are always executed unconditionally in the same sequence.
We can regroup these instructions in the same node that we are going to call \textbf{basic block}, representing the maximum sequence of instruction that are executed unconditionally in sequence. 
This greatly reduces the number of nodes present in the graph, reducing therefore the complexity of future computation on top of the graph.

\subsection{Formal definition of the checker}
\label{subsec:checker_formal_definition}
More formally, the idea is to check that the use of a pointer \emph{p} post dominates the check of \emph{p} for \emph{null}.
Intuitively, we can say that all path arriving to the check of \emph{p} goes through the use of \emph{p}, without having been reassigned between the two. 
To do this, we are going to use a data-flow analysis using the control flow graph previously described.

\subsubsection{Data-flow Analysis}
\label{subsubsec:data_flow_analysis}

The analysis tracks the pointer uses (set of pointer believed to be \emph{non-null}) and flag when the same pointer is checked afterwards.
The control flow graph will only be built for the current function being analyzed (intraprocedural), and will not have any access to other functions or others files (interprocedural).

Formally:

\begin{equation}\label{eqn:dataflow1}
i_{n} = o_{p1}  \cap   o_{p2}  \cap  ... \cap   o_{pk}
\end{equation}

Where $p1, ..., pk$ are all the predecessors, $i_{n}$ the input set, and  $o_{n}$ the output set of node \emph{n}.

\begin{equation}\label{eqn:dataflow2}
o_{n} = gen(n)  \cup   (i_{n} \setminus kill(n))
\end{equation}

Where

\begin{equation}\label{eqn:dataflow3}
gen(n) =\text{pointer that is used in node \emph{n}}
\end{equation}
\begin{equation}\label{eqn:dataflow4}
kill(n) = \text{assignment of pointer in node \emph{n}}
\end{equation}

Intuitively, we can see the analysis as follow:
\begin{enumerate}
	\item The set of believed to be \emph{non-null} pointer split at fork. \newline 
	\item On join, we take the intersection of incoming path, this means that we will remove the ones kill on at least one path. Also called \emph{MUST} analysis. \newline 
\end{enumerate}

\subsection{Variation of the check}
\label{subsec:rule_variation}

\begin{table}[h]
	\centering
	\caption{Number of issues per type of analysis, with the setup described in section \ref{subsec:experimental_setup}}
	\label{table:issue_per_analysis_type}
	\begin{tabular}{|c|c|c|}
		\hline
		\bf Analysis type &  \bf $\bf N^{\circ}$  of issues &  \bf False Positive $[\%]$ \\ \hline
		Forward - MUST &  32 &  0 \\ 
		Forward - MAY &  2500 & $> 90$  \\ 
		Backward - MUST &  65 & 80 \\ \hline
	\end{tabular}
\end{table}

The version described before shows one way of doing the analysis, there is multiple small variation that we can do on the analysis that will greatly influence the results.

\subsubsection{May vs Must analysis}
\label{subsubsec:may_vs_must}

With a MAY analysis, the computation of the input set from equation \ref{eqn:dataflow1} becomes:
\begin{equation}\label{eqn:mayvsmust}
i_{n} = o_{p1}  \cup   o_{p2}  \cup  ... \cup   o_{pk}
\end{equation}

If a \emph{MUST} analysis takes the intersection of all incoming path, the \emph{MAY} analysis takes the union of the paths. 
It means that a pointer will be removed from the set only if all path re-assign this variable.
The choice of \emph{MUST} over \emph{MAY} goes in the sense of the idea to have as little false positives as possible described \ref{subsubsec:precision_recall}.
Table \ref{table:issue_per_analysis_type} shows the difference between a \emph{MAY} and a \emph{MUST} analysis of the checker ran on the same sets of sources.
We can see that we have significantly more issues, but the rate of false positives is significantly higher, finding interesting issues is too hard with this noise. 
In addition, another downside of \emph{MAY} analysis is that identifying true positive can be tricky, involving only specific path executed that will raise an exception, while discovering false positive is straightforward.
In practice, to help the user to better understand the issue, we could report multiple locations, for example the line where the pointer is used, and the one where it is dereferenced.

Intuitively, it is not surprising that the \emph{MAY} analysis performs poorly if we do not take into account the paths that are unfeasible.

\lstinputlisting[label={lst:may-analysis-issue},
caption=False positive of MAY anaylsis]{code/may-analysis-fp.scala}

Listing \ref{lst:may-analysis-issue} shows an example of a false positive that is reported by the \emph{MAY} analysis. 
This is obviously an unfeasible path, the pointer \emph{p} at line $\#2$ is only used if it is not \emph{null}, the check for \emph{null} later at line $\#4$ does not mean that there is a potential exception.
We will discuss possible amelioration to this situation in subsection \ref{subsubsec:path_sensitivity}.

\subsubsection{Used then check, check then used}
\label{subsubsec:used_then_check_check_then_used}

\lstinputlisting[label={lst:used-then-check},
caption=Pointer that is used then checked]{code/used-then-check.scala}
\lstinputlisting[label={lst:checked-then-used},
caption=Pointer that is checked then used]{code/checked-then-used.scala}

Listing \ref{lst:used-then-check} and \ref{lst:checked-then-used} shows the difference between the two versions.
The work presented before implements the former, however, the latter makes as much sense, if all paths that follow the check for \emph{null} uses the pointer \emph{p}, without re-assigning it, it probably means that an error is possible.
In the implementation, this would be implemented using a backward analysis. 
As the name suggest, a backward analysis means that we take the intersection of all successorâ€™s input set to determine the output set of the current node. 

For a backward analysis, equation \ref{eqn:dataflow1} becomes:

\begin{equation}\label{eqn:checkthenused1}
o_{n} = i_{s1}  \cap   i_{s2}  \cap  ... \cap   i_{sk}
\end{equation}

Where $s1, ..., sk$ are all the successors of n.

And the computation \ref{eqn:dataflow2} from the forward analysis becomes:

\begin{equation}\label{eqn:checkthenused2}
i_{n} = gen(n)  \cup   (o_{n} \setminus kill(n))
\end{equation}

Surprisingly, the rate of FP is greatly increased, the number of false positive is greater than our goal of $<5\%$, but the issues are more interesting than the \emph{MAY} analysis, we can still find real issues, mainly due to the fact that identifying true positive is as easy as false positives.

\lstinputlisting[label={lst:user-define-function},
caption=User define function that changes the control flow]{code/user-define-function.scala} 

Listing \ref{lst:user-define-function} shows the typical example that generate the false positives, we can see that a function is called when \emph{p} is \emph{null}, that will throw an exception, therefore changing the execution flow order.

Custom functions that change the control flow is a weak point for flow based checker that does not perform interprocedural analysis, and we will probably face this problem both in an original language and in \slang{}. From now, we are only going to work with the first version (used then checked).




